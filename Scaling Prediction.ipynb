{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing Models for Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Graph Optimization Tool\n",
    "\n",
    "Note, this is for reference.  The full build takes ~ 30 minutes.  Your image already contains prebuilt binaries for graph transform tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "## install bazel\n",
    "#sudo apt-get install -y pkg-config zip g++ zlib1g-dev unzip python\n",
    "#wget https://github.com/bazelbuild/bazel/releases/download/0.16.0/bazel-0.16.0-installer-linux-x86_64.sh\n",
    "#chmod +x bazel-0.16.0-installer-linux-x86_64.sh\n",
    "#./bazel-0.16.0-installer-linux-x86_64.sh --user\n",
    "\n",
    "## build gtt and summarize graph\n",
    "#sudo apt-get install -y python3-numpy python3-dev python3-pip python3-wheel\n",
    "#git clone https://github.com/tensorflow/tensorflow\n",
    "#cd tensorflow\n",
    "#git checkout r1.10\n",
    "#bazel build tensorflow/tools/graph_transforms:transform_graph\n",
    "#bazel build tensorflow/tools/graph_transforms:summarize_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gsutil cp -r gs://tfs-data/models/mnist_cnn_model ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 possible inputs: (name=enqueue_input/Placeholder, type=int64(9), shape=<unknown>) (name=enqueue_input/Placeholder_1, type=float(1), shape=<unknown>) (name=enqueue_input/Placeholder_2, type=int32(3), shape=<unknown>) \n",
      "Found 11 variables: (name=global_step, type=int64(9), shape=[]) (name=conv1/W, type=float(1), shape=[5,5,1,64]) (name=conv1/b, type=float(1), shape=[64]) (name=conv2/W, type=float(1), shape=[5,5,64,64]) (name=conv2/b, type=float(1), shape=[64]) (name=Dense/W, type=float(1), shape=[3136,1024]) (name=Dense/b, type=float(1), shape=[1024]) (name=Output/W, type=float(1), shape=[1024,10]) (name=Output/b, type=float(1), shape=[10]) (name=accuracy/total, type=float(1), shape=[]) (name=accuracy/count, type=float(1), shape=[]) \n",
      "Found 21 possible outputs: (name=global_step/cond/switch_t, op=Identity) (name=global_step/cond/switch_f, op=Identity) (name=global_step/add, op=Add) (name=enqueue_input/random_shuffle_queue_EnqueueMany, op=QueueEnqueueManyV2) (name=enqueue_input/random_shuffle_queue_Close, op=QueueCloseV2) (name=enqueue_input/random_shuffle_queue_Close_1, op=QueueCloseV2) (name=ArgMax, op=ArgMax) (name=softmax, op=Softmax) (name=accuracy/value, op=Select) (name=gradients/sparse_softmax_cross_entropy_loss/value_grad/tuple/control_dependency_1, op=Identity) (name=gradients/sparse_softmax_cross_entropy_loss/div_grad/tuple/control_dependency_1, op=Identity) (name=gradients/sparse_softmax_cross_entropy_loss/Mul_grad/tuple/control_dependency_1, op=Identity) (name=gradients/zeros_like, op=ZerosLike) (name=gradients/dropout/mul_grad/tuple/control_dependency_1, op=Identity) (name=gradients/dropout/div_grad/tuple/control_dependency_1, op=Identity) (name=gradients/conv1/Conv2D_grad/tuple/control_dependency, op=Identity) (name=GradientDescent, op=AssignAdd) (name=concat, op=ConcatV2) (name=report_uninitialized_variables_1/boolean_mask/GatherV2, op=GatherV2) (name=Merge/MergeSummary, op=MergeSummary) (name=save/Identity, op=Identity) \n",
      "Found 1371 (1.37k) const parameters, 0 (0) variable parameters, and 114 control_edges\n",
      "92 nodes assigned to device '/device:CPU:0'Op types used: 149 Const, 43 Identity, 25 NoOp, 25 Reshape, 21 IsVariableInitialized, 20 Assign, 18 Sum, 17 Mul, 12 HistogramSummary, 11 VariableV2, 11 Add, 11 RealDiv, 8 ApplyGradientDescent, 7 Select, 7 BroadcastGradientArgs, 6 StridedSlice, 6 MatMul, 6 Cast, 5 Pack, 4 Fill, 4 TruncatedNormal, 4 ScalarSummary, 3 Relu, 3 ReluGrad, 3 Placeholder, 3 Equal, 3 Greater, 3 AssignAdd, 3 ConcatV2, 2 Switch, 2 Conv2DBackpropFilter, 2 Conv2DBackpropInput, 2 ShapeN, 2 Squeeze, 2 GatherV2, 2 Conv2D, 2 Sub, 2 QueueCloseV2, 2 Prod, 2 Tile, 2 LogicalNot, 2 MaxPool, 2 Neg, 2 MaxPoolGrad, 2 ArgMax, 2 Where, 1 ExpandDims, 1 StringJoin, 1 SparseSoftmaxCrossEntropyWithLogits, 1 Softmax, 1 ShardedFilename, 1 ZerosLike, 1 SaveV2, 1 RestoreV2, 1 Maximum, 1 Floor, 1 RefSwitch, 1 RandomUniform, 1 RandomShuffleQueueV2, 1 QueueSizeV2, 1 QueueEnqueueManyV2, 1 QueueDequeueManyV2, 1 PreventGradient, 1 Pow, 1 MergeV2Checkpoints, 1 MergeSummary, 1 Merge\n",
      "To use with tensorflow/tools/benchmark:benchmark_model try these arguments:\n",
      "bazel run tensorflow/tools/benchmark:benchmark_model -- --graph=mnist_cnn_model/graph.pbtxt --show_flops --input_layer=enqueue_input/Placeholder,enqueue_input/Placeholder_1,enqueue_input/Placeholder_2,global_step,conv1/W,conv1/b,conv2/W,conv2/b,Dense/W,Dense/b,Output/W,Output/b,accuracy/total,accuracy/count --input_layer_type=int64,float,int32,int64,float,float,float,float,float,float,float,float,float,float --input_layer_shape=::::5,5,1,64:64:5,5,64,64:64:3136,1024:1024:1024,10:10:: --output_layer=global_step/cond/switch_t,global_step/cond/switch_f,global_step/add,enqueue_input/random_shuffle_queue_EnqueueMany,enqueue_input/random_shuffle_queue_Close,enqueue_input/random_shuffle_queue_Close_1,ArgMax,softmax,accuracy/value,gradients/sparse_softmax_cross_entropy_loss/value_grad/tuple/control_dependency_1,gradients/sparse_softmax_cross_entropy_loss/div_grad/tuple/control_dependency_1,gradients/sparse_softmax_cross_entropy_loss/Mul_grad/tuple/control_dependency_1,gradients/zeros_like,gradients/dropout/mul_grad/tuple/control_dependency_1,gradients/dropout/div_grad/tuple/control_dependency_1,gradients/conv1/Conv2D_grad/tuple/control_dependency,GradientDescent,concat,report_uninitialized_variables_1/boolean_mask/GatherV2,Merge/MergeSummary,save/Identity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-06 22:54:16.364390: W tensorflow/tools/graph_transforms/summarize_graph_main.cc:225] Decoding Tensor failed for nodeglobal_step\n",
      "2018-08-06 22:54:16.364485: W tensorflow/tools/graph_transforms/summarize_graph_main.cc:225] Decoding Tensor failed for nodeconv1/W\n",
      "2018-08-06 22:54:16.364507: W tensorflow/tools/graph_transforms/summarize_graph_main.cc:225] Decoding Tensor failed for nodeconv1/b\n",
      "2018-08-06 22:54:16.364524: W tensorflow/tools/graph_transforms/summarize_graph_main.cc:225] Decoding Tensor failed for nodeconv2/W\n",
      "2018-08-06 22:54:16.364533: W tensorflow/tools/graph_transforms/summarize_graph_main.cc:225] Decoding Tensor failed for nodeconv2/b\n",
      "2018-08-06 22:54:16.364549: W tensorflow/tools/graph_transforms/summarize_graph_main.cc:225] Decoding Tensor failed for nodeDense/W\n",
      "2018-08-06 22:54:16.364558: W tensorflow/tools/graph_transforms/summarize_graph_main.cc:225] Decoding Tensor failed for nodeDense/b\n",
      "2018-08-06 22:54:16.364582: W tensorflow/tools/graph_transforms/summarize_graph_main.cc:225] Decoding Tensor failed for nodeOutput/W\n",
      "2018-08-06 22:54:16.364595: W tensorflow/tools/graph_transforms/summarize_graph_main.cc:225] Decoding Tensor failed for nodeOutput/b\n",
      "2018-08-06 22:54:16.364652: W tensorflow/tools/graph_transforms/summarize_graph_main.cc:225] Decoding Tensor failed for nodeaccuracy/total\n",
      "2018-08-06 22:54:16.364671: W tensorflow/tools/graph_transforms/summarize_graph_main.cc:225] Decoding Tensor failed for nodeaccuracy/count\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "tensorflow/bazel-bin/tensorflow/tools/graph_transforms/summarize_graph --in_graph=mnist_cnn_model/graph.pbtxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Graph Optimization Tool on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-06 23:29:23.986839: I tensorflow/tools/graph_transforms/transform_graph.cc:318] Applying strip_unused_nodes\n",
      "2018-08-06 23:29:23.988389: I tensorflow/tools/graph_transforms/transform_graph.cc:318] Applying remove_nodes\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "tensorflow/bazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\n",
    "--in_graph=mnist_cnn_model/graph.pbtxt \\\n",
    "--out_graph=mnist_cnn_model/optimized_model.pb \\\n",
    "--inputs='enqueue_input/Placeholder' \\\n",
    "--outputs='softmax' \\\n",
    "--transforms='\n",
    "strip_unused_nodes(type=float, shape=\"1,28,28,1\")\n",
    "remove_nodes(op=Identity, op=CheckNumerics)\n",
    "'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "tensorflow/bazel-bin/tensorflow/tools/graph_transforms/summarize_graph --in_graph=mnist_cnn_model/graph.pbtxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freeze the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lramsey/miniconda3/envs/tfs/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/lramsey/miniconda3/envs/tfs/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lramsey/serving-opt/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 382, in <module>\n",
      "    run_main()\n",
      "  File \"/home/lramsey/serving-opt/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 379, in run_main\n",
      "    app.run(main=my_main, argv=[sys.argv[0]] + unparsed)\n",
      "  File \"/home/lramsey/serving-opt/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/platform/app.py\", line 125, in run\n",
      "    _sys.exit(main(argv))\n",
      "  File \"/home/lramsey/serving-opt/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 378, in <lambda>\n",
      "    my_main = lambda unused_args: main(unused_args, flags)\n",
      "  File \"/home/lramsey/serving-opt/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 272, in main\n",
      "    flags.saved_model_tags, checkpoint_version)\n",
      "  File \"/home/lramsey/serving-opt/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 231, in freeze_graph\n",
      "    input_graph_def = _parse_input_graph_proto(input_graph, input_binary)\n",
      "  File \"/home/lramsey/serving-opt/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 174, in _parse_input_graph_proto\n",
      "    text_format.Merge(f.read(), input_graph_def)\n",
      "  File \"/home/lramsey/serving-opt/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/lib/io/file_io.py\", line 132, in read\n",
      "    pywrap_tensorflow.ReadFromStream(self._read_buf, length, status))\n",
      "  File \"/home/lramsey/serving-opt/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/lib/io/file_io.py\", line 100, in _prepare_value\n",
      "    return compat.as_str_any(val)\n",
      "  File \"/home/lramsey/serving-opt/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/util/compat.py\", line 107, in as_str_any\n",
      "    return as_str(value)\n",
      "  File \"/home/lramsey/serving-opt/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/util/compat.py\", line 80, in as_text\n",
      "    return bytes_or_text.decode(encoding)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xfe in position 1: invalid start byte\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph \\\n",
    "--input_graph=mnist_cnn_model/optimized_model.pb \\\n",
    "--input_checkpoint=mnist_cnn_model/model.ckpt-20000 \\\n",
    "--output_graph=mnist_cnn_model/frozen_graph.pb \\\n",
    "--output_node_names=softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No inputs spotted.\n",
      "No variables spotted.\n",
      "Found 1 possible outputs: (name=softmax, op=Softmax) \n",
      "Found 3326680 (3.33M) const parameters, 0 (0) variable parameters, and 0 control_edges\n",
      "Op types used: 16 Const, 8 Identity, 6 Add, 3 Relu, 3 Reshape, 2 Conv2D, 2 MatMul, 2 MaxPool, 2 Mul, 1 Floor, 1 QueueDequeueManyV2, 1 RandomShuffleQueueV2, 1 RandomUniform, 1 RealDiv, 1 Softmax, 1 Sub\n",
      "To use with tensorflow/tools/benchmark:benchmark_model try these arguments:\n",
      "bazel run tensorflow/tools/benchmark:benchmark_model -- --graph=mnist_cnn_model/frozen_graph.pb --show_flops --input_layer= --input_layer_type= --input_layer_shape= --output_layer=softmax\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "tensorflow/bazel-bin/tensorflow/tools/graph_transforms/summarize_graph --in_graph=mnist_cnn_model/frozen_graph.pb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
