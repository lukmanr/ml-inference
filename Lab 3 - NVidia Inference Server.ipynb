{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NVidia Inference Server\n",
    "\n",
    "## Setup account on NGC Cloud\n",
    "\n",
    "1. Go to http://ngc.nvidia.com and create an account.\n",
    "\n",
    "2. Generate an API Key.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NVidia Image (recommended)\n",
    "\n",
    "```\n",
    "export HOST_NAME=`whoami`-inference\n",
    "export PROJECT=$DEVSHELL_PROJECT_ID\n",
    "export ZONE=europe-west4-a\n",
    "\n",
    "gcloud beta compute --project \"$PROJECT\" \\\n",
    "  instances create \"$HOST_NAME\" \\\n",
    "  --zone \"$ZONE\" \\\n",
    "  --machine-type \"n1-standard-4\" \\\n",
    "  --subnet \"default\" \\\n",
    "  --maintenance-policy \"TERMINATE\" \\\n",
    "  --accelerator type=nvidia-tesla-p100,count=2 \\\n",
    "  --min-cpu-platform \"Automatic\" \\\n",
    "  --image nvidia-gpu-cloud-image-20180717 \\\n",
    "  --image-project nvidia-ngc-public \\\n",
    "  --boot-disk-size \"200GB\" \\\n",
    "  --boot-disk-type \"pd-standard\" \\\n",
    "  --boot-disk-device-name \"$HOSTNAME\" \\\n",
    "  --scopes=https://www.googleapis.com/auth/cloud-platform\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ubuntu 16.04\n",
    "\n",
    "### Install docker-engine and nvidia-docker\n",
    "\n",
    "This assumes Ubuntu 16.04.\n",
    "\n",
    "    sudo apt-get update && sudo apt-get install apt-transport-https ca-certificates curl -y\n",
    "    sudo apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 \\\n",
    "        --recv-keys 58118E89F3A912897C070ADBF76221572C52609D\n",
    "    echo \"deb https://apt.dockerproject.org/repo ubuntu-xenial main\" | sudo tee /etc/apt/sources.list.d/docker.list\n",
    "    sudo apt-get update\n",
    "    sudo apt-get -y install docker-engine=1.12.6-0~ubuntu-xenial\n",
    "\n",
    "    wget -P /tmp https://github.com/NVIDIA/nvidia-docker/releases/download/v1.0.1/nvidia-docker_1.0.1-1_amd64.deb\n",
    "    sudo dpkg -i /tmp/nvidia-docker*.deb && rm /tmp/nvidia-docker*.deb\n",
    "    \n",
    "    sudo usermod -a -G docker $USER\n",
    "\n",
    "(You may need to log out and log in again in order to run docker commands as non-sudo)\n",
    "\n",
    "\n",
    "### Start an Inference Server instance\n",
    "\n",
    "1. Browse to [Inference Server images](https://ngc.nvidia.com/registry/nvidia-inferenceserver)\n",
    "\n",
    "2. Login docker to NGC:\n",
    "\n",
    "```\n",
    "    docker login nvcr.io\n",
    "```\n",
    "\n",
    "You will be prompted to enter a Username and Password. Type “$oauthtoken” exactly as shown, and enter your NGC API key obtained during NGC account setup:\n",
    "\n",
    "```\n",
    "    Username: $oauthtoken\n",
    "    Password: <Your NGC API Key>\n",
    "```\n",
    " \n",
    "3. Pull container for inference server.\n",
    "\n",
    "```\n",
    "    docker pull nvcr.io/nvidia/inferenceserver:18.07-py3\n",
    "```\n",
    "\n",
    "4. Download sample Model Store (ResNet50 implemented in Caffe)\n",
    "\n",
    "```\n",
    "    git clone https://github.com/NVIDIA/dl-inference-server.git\n",
    "    cd dl-inference-store/examples\n",
    "    ./fetch_models.sh\n",
    "    cd ../..\n",
    "```\n",
    "\n",
    "4. Start the server instance\n",
    "\n",
    "```\n",
    "nvidia-docker run --rm --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 -p8000:8000 -p8001:8001 -v\"/home/lramsey/dl-inference-server/examples/models/resnet50_netdef\":\"/tmp/models\" nvcr.io/nvidia/inferenceserver:18.07-py3 /opt/inference_server/bin/inference_server --model-store=/tmp/models\n",
    "```\n",
    "\n",
    "The nvidia-docker -v option maps ./dl-inference-server/examples/models/resnet50_netdef on the host into the container at /tmp/models, and the --model-store option to the Inference Server is used to point to /tmp/models as the model store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
